"""
Music Extender
í•œ ê³¡ì„ ìì—°ìŠ¤ëŸ½ê²Œ ë°˜ë³µí•˜ì—¬ ê¸¸ì´ë¥¼ í™•ì¥í•˜ëŠ” ëª¨ë“ˆ
"""

import numpy as np
import librosa
import soundfile as sf
import os
import moviepy.editor as mp
from audio_analyzer import AudioAnalyzer
from advanced_mixer import AdvancedMixer


class MusicExtender:
    """ìŒì•… ë° ë¹„ë””ì˜¤ í™•ì¥ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.mixer = AdvancedMixer()
    
    def parse_duration(self, duration_str: str) -> float:
        """
        ì‹œê°„ ë¬¸ìì—´ì„ ì´ˆ ë‹¨ìœ„ë¡œ ë³€í™˜
        ì˜ˆ: '30m' -> 1800.0, '1h' -> 3600.0, '300s' -> 300.0
        """
        duration_str = duration_str.lower()
        if duration_str.endswith('m'):
            return float(duration_str[:-1]) * 60
        elif duration_str.endswith('h'):
            return float(duration_str[:-1]) * 3600
        elif duration_str.endswith('s'):
            return float(duration_str[:-1])
        else:
            return float(duration_str)
            
    def extend_track(self, input_path: str, output_path: str, 
                     target_duration_str: str, 
                     transition_bars: int = 16) -> str:
        """
        íŠ¸ë™(ì˜¤ë””ì˜¤, ë¹„ë””ì˜¤ ë˜ëŠ” ì´ë¯¸ì§€)ì„ ëª©í‘œ ì‹œê°„ê¹Œì§€ ë°˜ë³µ í™•ì¥
        """
        lower_path = input_path.lower()
        is_video = lower_path.endswith(('.mp4', '.mov', '.avi', '.mkv', '.webm'))
        is_image = lower_path.endswith(('.jpg', '.jpeg', '.png', '.webp', '.bmp'))
        is_media = is_video or is_image
        
        video_temp_audio = "temp_video_audio.wav"
        
        # ë¯¸ë””ì–´ì¸ ê²½ìš° ì˜¤ë””ì˜¤ ì¶”ì¶œ (ì´ë¯¸ì§€ëŠ” ì˜¤ë””ì˜¤ ì—†ìŒ)
        actual_input = input_path
        if is_video:
            print("ğŸ¬ Video detected. Extracting audio for processing...")
            video = mp.VideoFileClip(input_path)
            video.audio.write_audiofile(video_temp_audio, logger=None)
            actual_input = video_temp_audio
        elif is_image:
            print("ğŸ–¼ï¸ Image detected. Processing as a static background...")
            # ì´ë¯¸ì§€ëŠ” ì˜¤ë””ì˜¤ê°€ ì—†ìœ¼ë¯€ë¡œ ì‚¬ìš©ìê°€ ì´ì „ì— ì—…ë¡œë“œí•œ ì˜¤ë””ì˜¤ê°€ í•„ìš”í•˜ì§€ë§Œ,
            # í˜„ì¬ êµ¬ì¡°ìƒ 'ì´ë¯¸ì§€ + ì˜¤ë””ì˜¤' ë™ì‹œ ì—…ë¡œë“œ ê¸°ëŠ¥ì´ ì•„ë‹ˆë¯€ë¡œ 
            # ì—¬ê¸°ì„œëŠ” ë¶„ì„í•  ì˜¤ë””ì˜¤ê°€ í•„ìš”í•¨. 
            # ë§Œì•½ ì´ë¯¸ì§€ë§Œ ë„£ì—ˆë‹¤ë©´ ì—ëŸ¬ê°€ ë‚  ê²ƒì´ë¯€ë¡œ backendì—ì„œ ë°©ì–´í•´ì•¼í•¨.
            pass

        target_duration = self.parse_duration(target_duration_str)
        
        print(f"\n{'='*70}")
        print(f"ğŸ”„ Media Extender: Extending to {target_duration_str}")
        print(f"{'='*70}\n")
        
        # 1. ë¶„ì„ (ì´ë¯¸ì§€ì¸ ê²½ìš° ì˜¤ë””ì˜¤ ë¶„ì„ ë¶ˆê°€í•˜ë¯€ë¡œ ì²˜ë¦¬ í•„ìš”)
        print("ğŸ“Š Analyzing track...")
        analyzer = AudioAnalyzer(actual_input)
        analysis = analyzer.analyze_full()
        
        # 2. ì˜¤ë””ì˜¤ ë¡œë“œ
        print("\nğŸ“‚ Loading audio...")
        audio, sr = self.mixer.load_audio(input_path)
        original_duration = analysis['duration']
        
        # 3. ë°˜ë³µ íšŸìˆ˜ ê³„ì‚°
        # ì‹¤ì œ ë£¨í”„ë˜ëŠ” ê¸¸ì´ = ì „ì²´ ê¸¸ì´ - ë¯¹ìŠ¤ì•„ì›ƒ í¬ì¸íŠ¸ + ë¯¹ìŠ¤ì¸ í¬ì¸íŠ¸ (ëŒ€ëµ)
        # ì •í™•íˆëŠ” (Original Len - Transition Len) * N + Transition Len
        # í•˜ì§€ë§Œ transition pointê°€ ìœ ë™ì ì´ë¯€ë¡œ ë‹¨ìˆœí™”í•´ì„œ ê³„ì‚°
        
        # Outro start -> Intro end ì—°ê²°
        # ìµœì  ì „í™˜ ì°¾ê¸° (ìê¸° ìì‹ ê³¼ ë¯¹ì‹±í•˜ë¯€ë¡œ analysis1=analysis2)
        mixout_point, mixin_point = self.mixer.find_optimal_transition_point(
            analysis, analysis, transition_bars
        )
        
        # ë¹„íŠ¸ ì •ë ¬ (Mixin í¬ì¸íŠ¸ë¥¼ ë¹„íŠ¸ì— ë§ì¶¤)
        # ìê¸° ìì‹ ê³¼ ë¯¹ì‹±í•˜ë¯€ë¡œ BPM ë§¤ì¹­ ë¶ˆí•„ìš”
        
        # ìœ íš¨ ë£¨í”„ ê¸¸ì´ (í•œ ë²ˆ ë°˜ë³µë  ë•Œ ì¶”ê°€ë˜ëŠ” ì‹œê°„)
        loop_length_seconds = mixout_point - mixin_point
        if loop_length_seconds <= 0:
             # ë£¨í”„ ê¸¸ì´ê°€ 0ë³´ë‹¤ ì‘ìœ¼ë©´ ì „ì²´ ê¸¸ì´ ì‚¬ìš© (fallback)
             loop_length_seconds = original_duration * 0.8 
             mixout_point = original_duration * 0.9
             mixin_point = original_duration * 0.1
             
        required_loops = int(np.ceil((target_duration - mixin_point) / loop_length_seconds))
        
        print(f"\nTarget: {target_duration:.1f}s")
        print(f"Loop Length: {loop_length_seconds:.2f}s (Mixout: {mixout_point:.1f}s â†’ Mixin: {mixin_point:.1f}s)")
        print(f"Required loops: {required_loops}")
        
        if required_loops <= 1:
            print("âš ï¸  Target duration is shorter than original. Copying original.")
            sf.write(output_path, audio.T, sr)
            return output_path
            
        # 4. ë£¨í”„ ìƒì„±
        print(f"\nğŸ”¨ Building extended track ({required_loops} iterations)...")
        
        # ì²« ë²ˆì§¸ ë¸”ë¡ (ì²˜ìŒ ~ ë¯¹ìŠ¤ì•„ì›ƒ)
        # ì‹¤ì œë¡œëŠ” í¬ë¡œìŠ¤í˜ì´ë“œë¥¼ ìœ„í•´ ëê¹Œì§€ í•„ìš”í•  ìˆ˜ ìˆìŒ
        # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„ ìœ„í•´ ì „ì²´ë¥¼ í•œ ë²ˆì— ë¹Œë“œí•˜ì§€ ì•Šê³ , ì ì§„ì ìœ¼ë¡œ ì¶”ê°€
        
        current_audio = audio
        
        # ì§„í–‰ ìƒí™© í‘œì‹œë¥¼ ìœ„í•´
        import sys
        
        for i in range(required_loops - 1):
            sys.stdout.write(f"\r  Progress: {i+1}/{required_loops-1} loops mixed")
            sys.stdout.flush()
            
            # current_audioì˜ ëë¶€ë¶„(Outro)ê³¼ audioì˜ ì•ë¶€ë¶„(Intro)ì„ ë¯¹ì‹±
            
            # ë¹„íŠ¸ ì •ë ¬ ë° í¬ë¡œìŠ¤í˜ì´ë“œ
            # align_beats í•¨ìˆ˜ëŠ” audio2ë¥¼ ì´ë™ì‹œí‚¤ê±°ë‚˜ ìë¥´ëŠ”ë°, ì—¬ê¸°ì„œëŠ” audio2(ì›ë³¸)ì˜ ì‹œì‘ì ì„ ë§ì¶¤
            
            # ë¯¹ìŠ¤ì•„ì›ƒ í¬ì¸íŠ¸ëŠ” current_audio ê¸°ì¤€ (ëì—ì„œ loop_length ë§Œí¼ ì „ì´ ì•„ë‹ˆë¼, ë¶„ì„ëœ ì§€ì )
            # í•˜ì§€ë§Œ current_audioëŠ” ê³„ì† ê¸¸ì–´ì§€ë¯€ë¡œ, ë§¤ë²ˆ ê¸¸ì´ë¥¼ ì¬ê³„ì‚°í•´ì„œ ìƒëŒ€ ìœ„ì¹˜ë¥¼ ì°¾ì•„ì•¼ í•¨
            # ì²« ë²ˆì§¸ ë£¨í”„: mixout_point
            # ë‘ ë²ˆì§¸ ë£¨í”„: mixout_point + loop_length
            # ...
            
            # ë‹¨ìˆœí™”ë¥¼ ìœ„í•´:
            # 1. Base Audio ìƒì„± (ë°˜ë³µ íšŸìˆ˜ë§Œí¼)
            # 2. ê° ì ‘í•©ë¶€ì—ì„œ Crossfade ì ìš©
            pass
            
        # ë©”ëª¨ë¦¬ ë¬¸ì œ ë°©ì§€ë¥¼ ìœ„í•´ ì „ëµ ìˆ˜ì •:
        # Crossfadeë¶€ë¶„ë§Œ ê³„ì‚°í•˜ê³ , ë‚˜ë¨¸ì§€ëŠ” ê·¸ëŒ€ë¡œ ë¶™ì„
        
        # [Intro ... Body ... MixOutStart]  +  [MixInStart ... Body ... Outro]
        #                    \ Crossfade /
        
        # Part A: Start to MixOut
        part_a = audio[:, :int(mixout_point * sr)]
        
        # Part B: MixIn to End
        part_b = audio[:, int(mixin_point * sr):]
        
        # Crossfade Region Calculation
        # ë‘ ì˜¤ë””ì˜¤ë¥¼ ê²¹ì¹  ê¸¸ì´
        crossfade_duration = (60 / analysis['bpm']) * 4 * transition_bars
        crossfade_samples = int(crossfade_duration * sr)
        
        # ì‹¤ì œ ë¯¹ì‹± ë¡œì§
        # 1. ì²« ë²ˆì§¸ íŒŒíŠ¸ ì¤€ë¹„
        final_audio_parts = [audio[:, :int(mixout_point * sr)]]
        current_length = final_audio_parts[0].shape[1]
        
        # 2. ë£¨í”„ ì¶”ê°€
        # ì—¬ê¸°ì„œ 'ì •êµí•œ' ë¯¹ì‹±ì„ í•˜ë ¤ë©´ AdvancedMixer.create_crossfadeë¥¼ ì¨ì•¼ í•˜ëŠ”ë°
        # êµ¬ì¡°ìƒ ì•½ê°„ ë³µì¡í•¨. ì§ì ‘ êµ¬í˜„:
        
        # ë£¨í”„ì˜ í•µì‹¬ì€: [End of Prev]ì™€ [Start of Next]ë¥¼ ê²¹ì¹˜ëŠ” ê²ƒ
        # Prev: ... [FadeOut Region] ...
        # Next: [FadeIn Region] ...
        
        # ê°„ë‹¨í•œ ì ‘ê·¼:
        # 1. Main Body: (Mixin Point + Crossfade/2) ~ (Mixout Point - Crossfade/2)
        # 2. Transition Block: (Mixout - Crossfade/2) + (Mixin - Crossfade/2) -> Mixed
        
        # ë” ê°„ë‹¨í•œ ì ‘ê·¼ (DJ ìŠ¤íƒ€ì¼):
        # Base Loop: audio[Mixin_Point : Mixout_Point] (ì¤‘ê°„ ëª¸í†µ)
        # í•˜ì§€ë§Œ ì´ë ‡ê²Œ í•˜ë©´ Intro/Outroê°€ ì‚¬ë¼ì§.
        
        # Intro(0~Mixin) + [Body(Mixin~Mixout) * N] + Outro(Mixout~End)
        # ë¬¸ì œëŠ” Bodyì™€ Body ì‚¬ì´, Intro-Body ì‚¬ì´ì˜ ì—°ê²°ì´ ë§¤ë„ëŸ¬ì›Œì•¼ í•¨.
        
        # í•´ê²°ì±…:
        # Recursive approach using mixer.create_crossfade is memory intensive for long files.
        # But for MVP (30 mins), 300MB ~ 600MB RAM is okay.
        
        full_mix = audio
        
        for i in range(required_loops - 1):
            sys.stdout.write(f"\r  Progress: {i+1}/{required_loops-1}")
            sys.stdout.flush()
            
            # í˜„ì¬ ë¯¹ìŠ¤ì˜ ëë¶€ë¶„ê³¼ ì›ë³¸ì˜ ì•ë¶€ë¶„ì„ ë¯¹ì‹±
            # current_mixout = current_length - (original_duration - mixout_point)
            # ë„ˆë¬´ ë³µì¡í•¨.
            
            # "Append with Crossfade" ë°©ì‹
            # Prev Trackì˜ Mixout Point ì§€ì ë¶€í„° Next Trackì˜ Mixin Point ì§€ì ì„ ê²¹ì¹¨
            
            # 1. Prev Trackì˜ ë¯¹ìŠ¤ì•„ì›ƒ ì§€ì  ê³„ì‚° (ë§ˆì§€ë§‰ ì„¹ì…˜)
            # Prev Trackì˜ ê¸¸ì´ëŠ” ê³„ì† ë³€í•¨.
            # í•˜ì§€ë§Œ ë¯¹ì‹± í¬ì¸íŠ¸ëŠ” í•­ìƒ 'ëì—ì„œ (Duration - MixoutPoint) ì´ˆ ì „'ì„.
            
            time_from_end = original_duration - mixout_point
            current_mixout_index = full_mix.shape[1] - int(time_from_end * sr)
            
            # 2. Next Track (Original)ì˜ ë¯¹ìŠ¤ì¸ ì§€ì 
            next_mixin_index = int(mixin_point * sr)
            
            # 3. ê²¹ì¹˜ëŠ” êµ¬ê°„ (Crossfade length)
            # mixout_pointë¶€í„° crossfade_duration ë§Œí¼
            
            # ë¹„íŠ¸ ì •ë ¬ (ì´ë¯¸ ê°™ì€ ê³¡ì´ë¼ BPM ê°™ìŒ, ìœ„ìƒë§Œ ë§ì¶”ë©´ ë¨)
            # align_beats ë¡œì§ ì¬ì‚¬ìš©
            
            # ì˜ë¼ë‚´ê¸° ë° ë¶™ì´ê¸°
            # Prev: [Start ............ Mixout] (Fade Out)
            # Next:           [Mixin ............ End] (Fade In)
            
            # A: Prev before fade
            # B: Mixed part
            # C: Next after fade
            
            fade_start_idx = current_mixout_index
            fade_end_idx = fade_start_idx + crossfade_samples
            
            # Next track starts at: fade_start_idx corresponds to mixin_point in Next Track
            # But we need to align beats.
            
            # Beat alignment logic simplified for same track:
            # Just ensure we cut exactly at beats?
            # Let's trust mixout/mixin points provided by find_optimal_transition_point which aligns to beats.
            
            # Prev Trackì„ fade_start_idx + crossfade_samples ê¹Œì§€ë§Œ ìœ ì§€ (ë‚˜ë¨¸ì§€ ë²„ë¦¼)
            prev_keep = full_mix[:, :fade_end_idx]
            if prev_keep.shape[1] < fade_end_idx:
                # Pad if needed (shouldn't happen if mixout point is valid)
                pass
                
            # Next Track (Original) ì¤€ë¹„
            # mixin_pointë¶€í„° ì‹œì‘í•˜ë˜, crossfade_samples ë§Œí¼ì€ ê²¹ì¹¨
            next_start_idx = int(mixin_point * sr)
            next_audio = audio[:, next_start_idx:]
            
            # Crossfade ì ìš©
            # ê²¹ì¹˜ëŠ” ë¶€ë¶„: prev_keep[-crossfade_samples:] ê³¼ next_audio[:crossfade_samples]
            
            # Create curves
            fade_out = np.linspace(1, 0, crossfade_samples)
            fade_in = np.linspace(0, 1, crossfade_samples)
            
            # Overlap Area
            overlap_prev = prev_keep[:, -crossfade_samples:]
            overlap_next = next_audio[:, :crossfade_samples]
            
            # Mix overlap
            overlap_mixed = (overlap_prev * fade_out) + (overlap_next * fade_in)
            
            # Concat: [Prev Body] + [Overlap Mixed] + [Next Body]
            prev_body = prev_keep[:, :-crossfade_samples]
            next_body = next_audio[:, crossfade_samples:]
            
            # Combine
            full_mix = np.concatenate([prev_body, overlap_mixed, next_body], axis=1)
            
            # Stop if duration reached
            if full_mix.shape[1] / sr >= target_duration:
                break
                
        print(f"\nâœ… Extended logic complete. Final duration: {full_mix.shape[1]/sr:.1f}s")
        
        # Normalize
        full_mix = self.mixer.normalize_audio(full_mix)
        
        # Save Audio
        audio_output = output_path if not is_media else "temp_extended_audio.wav"
        sf.write(audio_output, full_mix.T, sr)
        print(f"ğŸ’¾ Saved audio to {audio_output}")
        
        # 6. ë¯¸ë””ì–´ ì²˜ë¦¬ (ë¹„ë””ì˜¤ ë˜ëŠ” ì´ë¯¸ì§€)
        if is_media:
            audio_clip = mp.AudioFileClip(audio_output)
            
            if is_video:
                print("\nğŸ¬ Looping video to match audio duration (Lofi-style/Seamless)...")
                video_clip = mp.VideoFileClip(input_path)
                
                # ì˜¤ë””ì˜¤ ë£¨í”„ í¬ì¸íŠ¸ì— ë§ì¶° ë¹„ë””ì˜¤ ì¡°ê°(Clip) ìƒì„±
                clips = []
                part_a = video_clip.subclip(0, mixout_point)
                clips.append(part_a)
                
                body_segment = video_clip.subclip(mixin_point, mixout_point)
                for _ in range(required_loops - 1):
                    clips.append(body_segment)
                    
                part_c = video_clip.subclip(mixin_point, video_clip.duration)
                clips.append(part_c)
                
                final_video = mp.concatenate_videoclips(clips, method="compose")
                final_video = final_video.set_duration(audio_clip.duration)
                for c in clips: c.close()
                video_clip.close()
            
            elif is_image:
                print("\nğŸ–¼ï¸ Creating static video from image...")
                final_video = mp.ImageClip(input_path).set_duration(audio_clip.duration)
            
            final_video = final_video.set_audio(audio_clip)
            
            print(f"ğŸ“¦ Writing final media: {output_path}")
            final_video.write_videofile(output_path, codec="libx264", audio_codec="aac", bitrate="5000k", logger=None)
            
            # Cleanup
            audio_clip.close()
            if os.path.exists(video_temp_audio): os.path.unlink(video_temp_audio)
            if os.path.exists("temp_extended_audio.wav"): os.path.unlink("temp_extended_audio.wav")
            
        return output_path

if __name__ == "__main__":
    import sys
    if len(sys.argv) < 3:
        print("Usage: python music_extender.py <input> <output> <duration>")
        sys.exit(1)
        
    extender = MusicExtender()
    extender.extend_track(sys.argv[1], sys.argv[2], sys.argv[3])
